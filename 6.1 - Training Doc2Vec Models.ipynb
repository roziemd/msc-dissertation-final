{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PPEbwq7_Jegx"
   },
   "source": [
    "# Training Doc2Vec Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wpCHdp3nJegy"
   },
   "source": [
    "## Import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Yk0YQAQ2Jegz",
    "outputId": "14e0db97-7e55-43ef-e694-02995c921a53"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned OFF\n"
     ]
    }
   ],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from nltk.tokenize import word_tokenize\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import collections\n",
    "from collections import Counter\n",
    "import re\n",
    "import math\n",
    "%matplotlib inline\n",
    "%pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2unp1hHZJeg6"
   },
   "source": [
    "## Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QmELcmIpJeg7"
   },
   "outputs": [],
   "source": [
    "def read_csv(path):\n",
    "    \n",
    "    \"\"\"This function reads a CSV file from a specified filepath, while preserving the data types of each variable.\n",
    "    Source: https://stackoverflow.com/questions/50047237/how-to-preserve-dtypes-of-dataframes-when-using-to-csv/50051542#50051542\"\"\"\n",
    "    \n",
    "    # Read types first line of csv\n",
    "    dtypes = {key:value for (key,value) in pd.read_csv(path, nrows=1).iloc[0].to_dict().items() if 'date' not in value}\n",
    "\n",
    "    parse_dates = [key for (key,value) in pd.read_csv(path, \n",
    "                   nrows=1).iloc[0].to_dict().items() if 'date' in value]\n",
    "    \n",
    "    # Read the rest of the lines with the types from above\n",
    "    return pd.read_csv(path, dtype=dtypes, parse_dates=parse_dates, skiprows=[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lqHlePe-JehC"
   },
   "outputs": [],
   "source": [
    "def cosine_similarity(A, B):\n",
    "    \n",
    "    \"\"\"This function takes two vectors as numpy arrays and computes the cosine similarity between them.\"\"\"\n",
    "\n",
    "    dot = np.dot(A, B)\n",
    "    norma = np.linalg.norm(A)\n",
    "    normb = np.linalg.norm(B)\n",
    "    cos = dot / (norma * normb)\n",
    "\n",
    "    return cos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H7kHDVUWJehI"
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    \n",
    "    \"\"\"This function transforms a value using the sigmoid function.\"\"\"\n",
    "    \n",
    "    return 1/(1+math.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ox2JEQl4JehO"
   },
   "outputs": [],
   "source": [
    "def compute_sdq_norm(X1, X2, X3):\n",
    "\n",
    "    \"\"\"This function computes normalised SDQ for a given a set of three cosine similarity scores, where:\n",
    "    1. X1 is the cosine similarity between Documents A and B;\n",
    "    2. X2 is the cosine similarity between Documents B and C; and \n",
    "    3. X3 is the cosine similarity between Documents A and C.\n",
    "    \"\"\"\n",
    "    \n",
    "    sdq_abs = (sigmoid(X1) / (sigmoid(X2) * sigmoid(X3)))\n",
    "    sdq_max = (sigmoid(1) / (sigmoid(-1) ** 2))\n",
    "    sdq_min = (sigmoid(-1) / (sigmoid(1) ** 2))\n",
    "    \n",
    "    return  ((sdq_abs - sdq_min))/(sdq_max - sdq_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4uzFWvQAJehS"
   },
   "outputs": [],
   "source": [
    "def train_doc2vec_model(corpus, vec_size, min_count, num_epochs, dm, alpha=0.025, min_alpha=0.00025):\n",
    "    \n",
    "    \"\"\"This function trains Doc2Vec models.\"\"\"\n",
    "    \n",
    "    # Instantiate the model\n",
    "    model = Doc2Vec(vector_size=vec_size, \n",
    "                    min_count=min_count, \n",
    "                    epochs=num_epochs, \n",
    "                    dm=dm,\n",
    "                    alpha=alpha, \n",
    "                    min_alpha=min_alpha) \n",
    "    \n",
    "    # Build vocab given the corpus\n",
    "    model.build_vocab(corpus)\n",
    "    \n",
    "    # Train model\n",
    "    model.train(corpus, total_examples=model.corpus_count, epochs=model.epochs)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1cFHWPn6JehV"
   },
   "outputs": [],
   "source": [
    "def average_sdq_norm(model, candidate_list):\n",
    "    \n",
    "    \"\"\"This function computes the average SDQ norm across all triplets of candidate scam reports.\"\"\"\n",
    "\n",
    "    similarity_indices = []\n",
    "\n",
    "    for i in range(len(candidate_list)):\n",
    "        A = model.infer_vector(candidate_list[i][0].split())\n",
    "        B = model.infer_vector(candidate_list[i][1].split())\n",
    "        C = model.infer_vector(candidate_list[i][2].split())\n",
    "        X1 = cosine_similarity(A, B)\n",
    "        X2 = cosine_similarity(A, C)\n",
    "        X3 = cosine_similarity(B, C)\n",
    "        similarity_indices.append(compute_sdq_norm(X1, X2, X3))\n",
    "\n",
    "    return round(np.mean(similarity_indices), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SYn4Y8yOJehe"
   },
   "outputs": [],
   "source": [
    "def compute_self_similarity(model, corpus):\n",
    "    \n",
    "    \"\"\"This function computes self-similarity index of a trained Doc2Vec model.\"\"\"\n",
    "\n",
    "    ranks = []\n",
    "\n",
    "    for doc_id in range(len(corpus)): \n",
    "\n",
    "        # Use the trained model of each epoch to infer vectors for each document in the validation data\n",
    "        inferred_vector = model.infer_vector(corpus[doc_id].words)\n",
    "\n",
    "        # Using the inferred vector, compute similarities with documents in the training data (It should be most similar to itself).\n",
    "        sims = model.docvecs.most_similar([inferred_vector], topn=len(model.docvecs))\n",
    "\n",
    "        # Create a list of document IDs in order of similarity to the current document\n",
    "        doc_list = [docid for docid, sim in sims]\n",
    "\n",
    "        # Extract the index position of the current document\n",
    "        rank = doc_list.index(doc_id)\n",
    "\n",
    "        # Append rank to the list, 'ranks'\n",
    "        ranks.append(rank)\n",
    "\n",
    "    # Perform a count of numbers in the list, 'ranks'\n",
    "    c = Counter(ranks)\n",
    "\n",
    "    # Compute the proportion of inferred vectors which correspond to the same document\n",
    "    perc_self_similar = [(i, c[i] / len(ranks)) for i in c][0][1]\n",
    "\n",
    "    return round(perc_self_similar, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tR8vwEwBJehh"
   },
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LXXZIhqbJehi",
    "outputId": "ea43605e-7b6c-4d85-9955-88b5156ec80d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>submission_id</th>\n",
       "      <th>preprocessed_text</th>\n",
       "      <th>scam_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20200717-fBLC6F</td>\n",
       "      <td>they call me by whatsapp it was strange for th...</td>\n",
       "      <td>Impersonation Scam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20200717-yOxIAl</td>\n",
       "      <td>it happened this morning hrs i received a phon...</td>\n",
       "      <td>Phishing Scam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20200717-Tz5TyW</td>\n",
       "      <td>i rceived a call from a lady claiming to be ca...</td>\n",
       "      <td>Phishing Scam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20200716-O79B6r</td>\n",
       "      <td>details i received a call from what seemed lik...</td>\n",
       "      <td>Impersonation Scam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20200716-yIa3LH</td>\n",
       "      <td>an impersonated junior technical staff called ...</td>\n",
       "      <td>Phishing Scam</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     submission_id                                  preprocessed_text  \\\n",
       "0  20200717-fBLC6F  they call me by whatsapp it was strange for th...   \n",
       "1  20200717-yOxIAl  it happened this morning hrs i received a phon...   \n",
       "2  20200717-Tz5TyW  i rceived a call from a lady claiming to be ca...   \n",
       "3  20200716-O79B6r  details i received a call from what seemed lik...   \n",
       "4  20200716-yIa3LH  an impersonated junior technical staff called ...   \n",
       "\n",
       "            scam_type  \n",
       "0  Impersonation Scam  \n",
       "1       Phishing Scam  \n",
       "2       Phishing Scam  \n",
       "3  Impersonation Scam  \n",
       "4       Phishing Scam  "
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = read_csv(\"Data/scam_data_4.csv\")[['submission_id', 'preprocessed_text', 'scam_type']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZTy6aYfkJehm"
   },
   "outputs": [],
   "source": [
    "corpus = [TaggedDocument(words=word_tokenize(_d.lower()), tags=[i]) for i, _d in enumerate(list(df['preprocessed_text']))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wiS6CAbrJehr"
   },
   "source": [
    "Example of how the first scam report in the corpus looks like..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bHIT0DBMJehs",
    "outputId": "66eda6ad-5bcd-43d4-912f-00bcb645fc96"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TaggedDocument(words=['they', 'call', 'me', 'by', 'whatsapp', 'it', 'was', 'strange', 'for', 'this', 'number', 'but', 'dbs', 'bank', 'logo', 'convinced', 'me', 'to', 'answer', '.', 'the', 'whatsapp', 'profile', 'was', 'dbslogo', ',', 'so', 'i', 'answer', ',', 'and', 'they', 'say', 'my', 'card', 'was', 'blocked', '.', 'then', 'they', 'ask', 'me', 'my', 'identity', 'number', '....', 'this', 'finally', 'explain', 'me', 'that', 'it', 'was', 'false', '.', 'so', 'i', 'replied', 'saying', 'that', 'i', 'would', 'go', 'to', 'the', 'branch', 'for', 'my', 'card', '.', 'they', 'triedto', 'convince', 'me', 'to', 'do', 'at', 'the', 'phone', ',', 'but', 'i', 'will', 'not', 'give', 'them', 'any', 'data', '.', 'they', 'then', 'ended', 'the', 'call', '.'], tags=[0])"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-G5RXAyfJehy"
   },
   "source": [
    "## Preparing candidate text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pIDQVMbWJeh0"
   },
   "source": [
    "This section finds triplets of three scam reports, where two scam reports are similar to each other and a third scam report is dissimilar to the first two. Eight triplets have been identified and pre-selected, and saved as the CSV file, `scam_candidate.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "45RwcpKkJeh1"
   },
   "outputs": [],
   "source": [
    "# search_word = \"sex scam\"\n",
    "# idx_list = []\n",
    "# data_list = list(df['preprocessed_text'])\n",
    "# for i in range(len(data_list)):\n",
    "#     idx_list.append(i) if re.search(search_word.lower(), data_list[i].lower()) else None\n",
    "# print(idx_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "isO8lkW1Jeh6"
   },
   "outputs": [],
   "source": [
    "# # Store the indices of pre-inspected candidate reports in a list\n",
    "# candidate_text_idx = [157, 159, 2751, 404, 10, 1841, 602, 711, 2944, 1161, 815, 2922, 3602, 3896, 1497, \\\n",
    "#                       1755, 1753, 2843, 322, 421, 758, 435, 449, 305]\n",
    "\n",
    "# # Slice the original dataframe to subset the candidate reports only\n",
    "# candidate_text = df.iloc[candidate_text_idx, [1,2]]\n",
    "\n",
    "# # Save as CSV file\n",
    "# candidate_text.to_csv(\"Data/scam_candidate.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GpVnCIgfJeiA"
   },
   "source": [
    "## Load candidate text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r8mkhvB7JeiB"
   },
   "outputs": [],
   "source": [
    "# Load the CSV file as a dataframe\n",
    "candidate_text = pd.read_csv(\"Data/scam_candidate.csv\")\n",
    "\n",
    "# Create a list of candidate text\n",
    "candidate_text_list = list(candidate_text['preprocessed_text'])\n",
    "\n",
    "# Create a list of 3 lists each\n",
    "candidate_text_list = [candidate_text_list[i*3:i*3+3] for i in range(int(len(candidate_text_list)/3))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ircScepJJeiF"
   },
   "source": [
    "### An example of a set of candidate texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GPt-j_8BJeiG",
    "outputId": "385b3281-92b0-4403-8eed-c9d3bc4e494b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_74a72f36_ec39_11ea_8563_7c2a31c2ff2drow0_col0 {\n",
       "            width:  500px;\n",
       "        }    #T_74a72f36_ec39_11ea_8563_7c2a31c2ff2drow1_col0 {\n",
       "            width:  500px;\n",
       "        }    #T_74a72f36_ec39_11ea_8563_7c2a31c2ff2drow2_col0 {\n",
       "            width:  500px;\n",
       "        }</style><table id=\"T_74a72f36_ec39_11ea_8563_7c2a31c2ff2d\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >preprocessed_text</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_74a72f36_ec39_11ea_8563_7c2a31c2ff2dlevel0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_74a72f36_ec39_11ea_8563_7c2a31c2ff2drow0_col0\" class=\"data row0 col0\" >automated phone call claiming it was from ministry_of_health with urgent information and to press 3 for more details. then a person came on the line speaking chinese, when i spoke english they hung up.</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_74a72f36_ec39_11ea_8563_7c2a31c2ff2dlevel0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "                        <td id=\"T_74a72f36_ec39_11ea_8563_7c2a31c2ff2drow1_col0\" class=\"data row1 col0\" >1 received a voice automated call from ministry_of_health asking me to follow their instructions as there is urgent information required by me.2 no money was lost</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_74a72f36_ec39_11ea_8563_7c2a31c2ff2dlevel0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "                        <td id=\"T_74a72f36_ec39_11ea_8563_7c2a31c2ff2drow2_col0\" class=\"data row2 col0\" >receiving calls recently from the number <telnum> originating from switzerland, suspect it could be related to wangiri scam. usually is a missed call, but if attend i hear automated voice of a lady saying hello darling, which i believe is targeted for guys to attract and trigger to call back them to charge call money value. luckily read few articles about the scam and have blocked it.</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler object at 0x000001580724AD08>"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e1 = candidate_text[['preprocessed_text']][0:3]\n",
    "e1.style.set_properties(subset=['preprocessed_text'], **{'width': '500px'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a7zihaGkJeiO"
   },
   "source": [
    "### Another example of a set of candidate texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BJr7HYHUJeiP",
    "outputId": "ca035ce2-dd52-496c-cc77-9f14d343fd71"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_764527d2_ec39_11ea_84e3_7c2a31c2ff2drow0_col0 {\n",
       "            width:  500px;\n",
       "        }    #T_764527d2_ec39_11ea_84e3_7c2a31c2ff2drow1_col0 {\n",
       "            width:  500px;\n",
       "        }    #T_764527d2_ec39_11ea_84e3_7c2a31c2ff2drow2_col0 {\n",
       "            width:  500px;\n",
       "        }</style><table id=\"T_764527d2_ec39_11ea_84e3_7c2a31c2ff2d\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >preprocessed_text</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_764527d2_ec39_11ea_84e3_7c2a31c2ff2dlevel0_row0\" class=\"row_heading level0 row0\" >3</th>\n",
       "                        <td id=\"T_764527d2_ec39_11ea_84e3_7c2a31c2ff2drow0_col0\" class=\"data row0 col0\" >received a scam call today from <telnum>. it was an indian female with a strong accent, claiming to be olivia smith from singtel calling to check on suspicious connections on my internet. she gave me a number to call back <telnum> and said her employee identity was dcl00198. when i asked her to verify that she is a singtel officer, she hung up.</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_764527d2_ec39_11ea_84e3_7c2a31c2ff2dlevel0_row1\" class=\"row_heading level0 row1\" >4</th>\n",
       "                        <td id=\"T_764527d2_ec39_11ea_84e3_7c2a31c2ff2drow1_col0\" class=\"data row1 col0\" >a lady claimed her name as olivia, calling from singtel tech department, employee number tlc00198. told me there is people stealing my internet, asked me to open my laptop terminal and execute netstat command, then explained to me what she made up how my ip has been misused by both domestic and foreign people. she was about to transfer me to another so called technical engineer before i hang up. she said she is authorized to resolve this today and asked me to call her back at <telnum>.called my telco company and verified, this is totally a scam. do not trust the scammers.</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_764527d2_ec39_11ea_84e3_7c2a31c2ff2dlevel0_row2\" class=\"row_heading level0 row2\" >5</th>\n",
       "                        <td id=\"T_764527d2_ec39_11ea_84e3_7c2a31c2ff2drow2_col0\" class=\"data row2 col0\" >since 1st august 2018, i am getting numerous calls from this 370 numbers.i have not pick up or called this number because its checked coming from lithuania country which never makes sense since i do not have any business or partners over there. i have blocked these numbers on my phone but apparently getting calls with 370 with new extension numbers.advice please do not call back or receive call. its a wangiri scam dr.ptbn</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler object at 0x000001580724A748>"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e2 = candidate_text[['preprocessed_text']][3:6]\n",
    "e2.style.set_properties(subset=['preprocessed_text'], **{'width': '500px'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1CQWj2PEJeiU"
   },
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XYHVjP_ZJeiU"
   },
   "source": [
    "### Experiment with different parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SvE7VKIVJeiV"
   },
   "source": [
    "Here, we train doc2vec models using different combinations of parameters. The objective is to select the set of parameters which produces the most optimal Doc2Vec model in terms of (1) Average Similarity Index and (2) Self Similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pyiqnSJ6JeiW"
   },
   "outputs": [],
   "source": [
    "num_epochs = [10, 25, 50, 100]\n",
    "num_dim = [20, 30, 40, 50]\n",
    "dm = [0, 1]\n",
    "min_count = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Jc8w9n_0Jeib",
    "outputId": "18d96670-c42a-4874-f821-d9ba3bb00d0e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 epochs, 20 dimensions, dm = 0 --> ASI: 0.158610 | SS: 0.714540\n",
      "Model saved at Models/Doc2Vec/doc2vec_model_1.model \n",
      "\n",
      "10 epochs, 20 dimensions, dm = 1 --> ASI: 0.181750 | SS: 0.729910\n",
      "Model saved at Models/Doc2Vec/doc2vec_model_2.model \n",
      "\n",
      "10 epochs, 30 dimensions, dm = 0 --> ASI: 0.157200 | SS: 0.731440\n",
      "Model saved at Models/Doc2Vec/doc2vec_model_3.model \n",
      "\n",
      "10 epochs, 30 dimensions, dm = 1 --> ASI: 0.201230 | SS: 0.864730\n",
      "Model saved at Models/Doc2Vec/doc2vec_model_4.model \n",
      "\n",
      "10 epochs, 40 dimensions, dm = 0 --> ASI: 0.157520 | SS: 0.714100\n",
      "Model saved at Models/Doc2Vec/doc2vec_model_5.model \n",
      "\n",
      "10 epochs, 40 dimensions, dm = 1 --> ASI: 0.192390 | SS: 0.912170\n",
      "Model saved at Models/Doc2Vec/doc2vec_model_6.model \n",
      "\n",
      "10 epochs, 50 dimensions, dm = 0 --> ASI: 0.157460 | SS: 0.689940\n",
      "Model saved at Models/Doc2Vec/doc2vec_model_7.model \n",
      "\n",
      "10 epochs, 50 dimensions, dm = 1 --> ASI: 0.192450 | SS: 0.926440\n",
      "Model saved at Models/Doc2Vec/doc2vec_model_8.model \n",
      "\n",
      "25 epochs, 20 dimensions, dm = 0 --> ASI: 0.190760 | SS: 0.995610\n",
      "Model saved at Models/Doc2Vec/doc2vec_model_9.model \n",
      "\n",
      "25 epochs, 20 dimensions, dm = 1 --> ASI: 0.199120 | SS: 0.972330\n",
      "Model saved at Models/Doc2Vec/doc2vec_model_10.model \n",
      "\n",
      "25 epochs, 30 dimensions, dm = 0 --> ASI: 0.193280 | SS: 0.996270\n",
      "Model saved at Models/Doc2Vec/doc2vec_model_11.model \n",
      "\n",
      "25 epochs, 30 dimensions, dm = 1 --> ASI: 0.208830 | SS: 0.989460\n",
      "Model saved at Models/Doc2Vec/doc2vec_model_12.model \n",
      "\n",
      "25 epochs, 40 dimensions, dm = 0 --> ASI: 0.193180 | SS: 0.996930\n",
      "Model saved at Models/Doc2Vec/doc2vec_model_13.model \n",
      "\n",
      "25 epochs, 40 dimensions, dm = 1 --> ASI: 0.204060 | SS: 0.991660\n",
      "Model saved at Models/Doc2Vec/doc2vec_model_14.model \n",
      "\n",
      "25 epochs, 50 dimensions, dm = 0 --> ASI: 0.195370 | SS: 0.997580\n",
      "Model saved at Models/Doc2Vec/doc2vec_model_15.model \n",
      "\n",
      "25 epochs, 50 dimensions, dm = 1 --> ASI: 0.208980 | SS: 0.994070\n",
      "Model saved at Models/Doc2Vec/doc2vec_model_16.model \n",
      "\n",
      "50 epochs, 20 dimensions, dm = 0 --> ASI: 0.213230 | SS: 0.997360\n",
      "Model saved at Models/Doc2Vec/doc2vec_model_17.model \n",
      "\n",
      "50 epochs, 20 dimensions, dm = 1 --> ASI: 0.204910 | SS: 0.996050\n",
      "Model saved at Models/Doc2Vec/doc2vec_model_18.model \n",
      "\n",
      "50 epochs, 30 dimensions, dm = 0 --> ASI: 0.206790 | SS: 0.998020\n",
      "Model saved at Models/Doc2Vec/doc2vec_model_19.model \n",
      "\n",
      "50 epochs, 30 dimensions, dm = 1 --> ASI: 0.215220 | SS: 0.997150\n",
      "Model saved at Models/Doc2Vec/doc2vec_model_20.model \n",
      "\n",
      "50 epochs, 40 dimensions, dm = 0 --> ASI: 0.202170 | SS: 0.996710\n",
      "Model saved at Models/Doc2Vec/doc2vec_model_21.model \n",
      "\n",
      "50 epochs, 40 dimensions, dm = 1 --> ASI: 0.212460 | SS: 0.996490\n",
      "Model saved at Models/Doc2Vec/doc2vec_model_22.model \n",
      "\n",
      "50 epochs, 50 dimensions, dm = 0 --> ASI: 0.207070 | SS: 0.997150\n",
      "Model saved at Models/Doc2Vec/doc2vec_model_23.model \n",
      "\n",
      "50 epochs, 50 dimensions, dm = 1 --> ASI: 0.218360 | SS: 0.996930\n",
      "Model saved at Models/Doc2Vec/doc2vec_model_24.model \n",
      "\n",
      "100 epochs, 20 dimensions, dm = 0 --> ASI: 0.218600 | SS: 0.997150\n",
      "Model saved at Models/Doc2Vec/doc2vec_model_25.model \n",
      "\n",
      "100 epochs, 20 dimensions, dm = 1 --> ASI: 0.210840 | SS: 0.997580\n",
      "Model saved at Models/Doc2Vec/doc2vec_model_26.model \n",
      "\n",
      "100 epochs, 30 dimensions, dm = 0 --> ASI: 0.210720 | SS: 0.996710\n",
      "Model saved at Models/Doc2Vec/doc2vec_model_27.model \n",
      "\n",
      "100 epochs, 30 dimensions, dm = 1 --> ASI: 0.219370 | SS: 0.997800\n",
      "Model saved at Models/Doc2Vec/doc2vec_model_28.model \n",
      "\n",
      "100 epochs, 40 dimensions, dm = 0 --> ASI: 0.211150 | SS: 0.997800\n",
      "Model saved at Models/Doc2Vec/doc2vec_model_29.model \n",
      "\n",
      "100 epochs, 40 dimensions, dm = 1 --> ASI: 0.214540 | SS: 0.997580\n",
      "Model saved at Models/Doc2Vec/doc2vec_model_30.model \n",
      "\n",
      "100 epochs, 50 dimensions, dm = 0 --> ASI: 0.208670 | SS: 0.998240\n",
      "Model saved at Models/Doc2Vec/doc2vec_model_31.model \n",
      "\n",
      "100 epochs, 50 dimensions, dm = 1 --> ASI: 0.224500 | SS: 0.997580\n",
      "Model saved at Models/Doc2Vec/doc2vec_model_32.model \n",
      "\n"
     ]
    }
   ],
   "source": [
    "avg_sdq_norm = []\n",
    "self_similarity = []\n",
    "suffix = 1\n",
    "\n",
    "for i in range(len(num_epochs)):\n",
    "    for j in range(len(num_dim)):\n",
    "        for k in range(2):\n",
    "            \n",
    "            # Train the model\n",
    "            model = train_doc2vec_model(corpus=corpus, vec_size=num_dim[j], min_count=2, num_epochs=num_epochs[i], dm=dm[k])\n",
    "            \n",
    "            # For each model, compute average similarity index when compared against the candidate set\n",
    "            sdq_norm = average_sdq_norm(model, candidate_text_list)\n",
    "            avg_sdq_norm.append(sdq_norm)\n",
    "            \n",
    "            # Also compute self similarity score\n",
    "            ssi = compute_self_similarity(model, corpus)\n",
    "            self_similarity.append(ssi)\n",
    "            print(\"%d epochs, %d dimensions, dm = %d --> Normalised SDQ : %f | SSI: %f\" % (num_epochs[i], num_dim[j], dm[k], sdq_norm, ssi))\n",
    "\n",
    "            # Save each model \n",
    "            path = \"Models/Doc2Vec/\" + \"doc2vec_model_\" + str(suffix) + \".model\"\n",
    "            model.save(path)\n",
    "            print(\"Model saved at \" + path, \"\\n\")\n",
    "            suffix += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PrRdG-7aJeif"
   },
   "source": [
    "## Saving the results as CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NWE_PAOIJeig"
   },
   "outputs": [],
   "source": [
    "epoch_list = [[10] * 8, [25] * 8, [50] * 8, [100] * 8]\n",
    "epoch_list = [j for i in epoch_list for j in i]\n",
    "\n",
    "dim_list = [[20] * 2, [30] * 2, [40] * 2, [50] * 2]\n",
    "dim_list = [[j for i in dim_list for j in i] * 4][0]\n",
    "\n",
    "dm_list = [[0, 1] * 16][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cpX2_IK-Jeij",
    "outputId": "2f08cc71-ac2b-4a9d-ee84-178ccc950f6e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_epoch</th>\n",
       "      <th>num_dim</th>\n",
       "      <th>dm_mode</th>\n",
       "      <th>ASI</th>\n",
       "      <th>SS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0.15861</td>\n",
       "      <td>0.71454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>0.18175</td>\n",
       "      <td>0.72991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0.15720</td>\n",
       "      <td>0.73144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0.20123</td>\n",
       "      <td>0.86473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0.15752</td>\n",
       "      <td>0.71410</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_epoch  num_dim  dm_mode      ASI       SS\n",
       "0         10       20        0  0.15861  0.71454\n",
       "1         10       20        1  0.18175  0.72991\n",
       "2         10       30        0  0.15720  0.73144\n",
       "3         10       30        1  0.20123  0.86473\n",
       "4         10       40        0  0.15752  0.71410"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc2vec_results = pd.DataFrame({'num_epoch': epoch_list, 'num_dim': dim_list, 'dm_mode': dm_list, 'SDQ_norm':avg_sdq_norm, 'SSI':self_similarity})\n",
    "doc2vec_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "onQKO3TGJeio"
   },
   "outputs": [],
   "source": [
    "doc2vec_results.to_csv(\"Results/doc2vec_results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "94OapquaJeiu"
   },
   "source": [
    "## Varying number of epochs (num dim = 50; PV-DM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k5jSGmjjJeiv"
   },
   "outputs": [],
   "source": [
    "num_epochs = [25, 50, 75, 100, 125, 150, 175, 200, 225, 250, 275, 300, 350, 400, 450, 500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sv4THqhqJei1",
    "outputId": "ce304f1f-63e5-4c7a-9bd8-4e9107fe64e9"
   },
   "outputs": [],
   "source": [
    "avg_sdq_norm = []\n",
    "self_similarity = []\n",
    "suffix = 1\n",
    "\n",
    "for i in range(len(num_epochs)):   \n",
    "    \n",
    "    # Train the model\n",
    "    model = train_doc2vec_model(corpus=corpus, vec_size=50, min_count=2, num_epochs=num_epochs[i], dm=1)\n",
    "\n",
    "    # For each model, compute average SDQ norm when compared against the candidate set\n",
    "    sdq_norm = average_sdq_norm(model, candidate_text_list)\n",
    "    avg_sdq_norm.append(sdq_norm)\n",
    "\n",
    "    # Also compute self similarity score\n",
    "    ssi = compute_self_similarity(model, corpus)\n",
    "    self_similarity.append(ssi)\n",
    "    print(\"%d epochs, 50 dimensions, dm = PV-DM --> Normalised SDQ: %f | SSI: %f\" % (num_epochs[i], sdq_norm, ssi))\n",
    "    \n",
    "    # Save each model \n",
    "    path = \"Models/Doc2Vec_50D_PVDM/\" + \"doc2vec_model_\" + str(suffix) + \".model\"\n",
    "    model.save(path)\n",
    "    print(\"Model saved at \" + path, \"\\n\")\n",
    "    suffix += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2vec_results_50D_PVDM = pd.DataFrame({'num_epochs': num_epochs, 'SDQ_norm':avg_sdq_norm, 'SSI':self_similarity})\n",
    "doc2vec_results_50D_PVDM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2vec_results_50D_PVDM.to_csv(\"Results/doc2vec_results_50D_PVDM.csv\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "6.1 - Training Doc2Vec Models.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
